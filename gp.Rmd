---
title: 'Gaussian Processes'
output: html_document
---


```{r gp, echo=F, fig.ext='svg'}
library(DiagrammeR)
gp_nodes = create_nodes(    
  nodes = c('gpm','gpsq', 'gpexp', 'gprq', 'gplin', 'gpother', 'GP', 
            'rkhs','ar1','ou', 'splines', 'GAM', 'SVM', 'NN', 'bayesreg'),
  label = c('GP w/ Matern', 'GP w/ SqExp', 'GP w/ Exp', 'GP w/ RQ', 'GP w/ linear', 'GP w/ Other', 'GP', 
            'RKHS', 'AR(p)', 'OU', 'Splines', 'GAM', 'SVM', 'NN', 'Bayesian\nRegression'),
  # type = 'a',
  # value = 1,
  
  style = 'filled',
  shape = 'circle',
  fixedsize=T,
  distortion='',
  color=c(rep('#8B000040', 6), 'lightblue', rep('#8B000040', 20)),
  fillcolor='papayawhip',
  fixedsize='',
  fontcolor='darkred',
  fontname='Roboto',
  fontsize=6,
  height='',
  penwidth='',
  peripheries=c(rep('1', 6), '4'),
  sides='',
  tooltip='',
  width='',
  x='',
  y='')

gp_edges = create_edges(
  from = c('gpm','ou', 'gpm','gpexp','gpm','rkhs','GP', 'gprq','GP', 'gpother', 
           'SVM', 'NN', 'gpother', 'GAM', 'gpsq', 'GP', 'gplin', 'GP'),
  to =   c('ar1','ar1', 'gpsq', 'ou','gpexp', 'GP', 'gpm','gpsq', 'gpother', 'splines', 
           'gpother', 'gpother', 'GAM', 'splines', 'gpexp', 'gplin', 'bayesreg', 'gprq'),
  # rel = c('a'),
  arrowhead='dot',
  arrowsize='.5',
  arrowtail='',
  color= '#FA8072BF', #'#8B000040',
  dir=c('', '','', 'none', '', 'none', '', '', '', '', 
        'none', 'none', '', '', '', '', 'none', ''),
  fontcolor='',
  fontname='',
  fontsize='',
  headport='',
  label=rep('&nbsp;', length=18),
  minlen='',
  penwidth='2',
  tailport='',
  tooltip=c('Matern with &nu; fixed to p-1/2', 
            'AR(p) is discretized version of OU', 
            'Matern with &nu; = &infin;',
            '&equiv;',
            'Matern with &nu; = 1/2',
            '',
            '',
            'RQ is a mixture of SQExp; &alpha; = &infin;',
            '',
            '',
            '',
            '',
            'thin plate, duchon spline',
            '',
            '',
            '',
            '&equiv;',
            '')
)
save(gp_nodes, gp_edges, file='data/gp.RData')
render_graph(create_graph(gp_nodes, gp_edges, graph_name='Gaussian Processes'), height = 1000, width = 750)
# pl = DiagrammeRsvg::export_svg(render_graph(create_graph(gp_nodes, gp_edges, graph_name='Gaussian Processes'), height = 1000, width = 750))
# htmltools::html_print(htmltools::HTML(pl))
```

## Connections to Gaussian processes

Hover over the links for details on *some* connections (i.e. not all edges have details).  Dots indicate 'special cases of' the parent node. Undirected connections suggest equivalence (&equiv; on hover) or a more complex relationship (usually for more general/more complex models).  Note this is for a quick reference, not an exhaustive one.


#### Matern class

Note that covariance functions are written identically in slightly different ways in different sources, and this is just one representation.  See the Rasmussen and Williams link for details.

$$h^2\frac{2^{1-\nu}}{\Gamma(\nu)}(2\sqrt{\nu}\frac{|x_i-x_j|}{\lambda})\mathcal{B}_\nu(2\sqrt{\nu}\frac{|x_i-x_j|}{\lambda})$$


$\lambda$ = horizontal/input length-scale

$h$ = vertical/output length-scale

$\nu$ = controls differentiability

$\Gamma$ = Gamma function

$\mathcal{B}$ = modified Bessel function of the second kind

## Labels


**GP**: Gaussian process

**Matern**: Matern covariance structure

**Exp**:  exponential covariance structure $h^2\exp(-\frac{|x_i-x_j|}{\lambda})$

**SqExp**: squared exponential covariance structure $h^2\exp[-(\frac{|x_i-x_j|}{\lambda})^2]$

**RQ**: rational quadratic covariance structure $h^2(1 + \frac{|x_i-x_j|^2}{\alpha\lambda^2})^{-\alpha}$

**Other**: other covariance functions

**OU**: Ornstein-Uhlenbeck process

**GAM**: generalized additive models

**Splines**: piecewise polynomial, regression splines

**SVM**: support vector machines

**NN**: neural networks

**RKHS**: reproducing kernel hilbert space


## References

- Rasmussen & Williams (2006). [Gaussian Processes for Machine Learning](http://www.gaussianprocess.org/gpml).
- Murphy (2012). Machine Learning: A probabilistic perspective.
- [The kernel cookbook](http://www.cs.toronto.edu/~duvenaud/cookbook/); [pdf chapter](https://raw.githubusercontent.com/duvenaud/phd-thesis/master/kernels.pdf)

#### Stack 

- [AR-OU](http://math.stackexchange.com/questions/345773/how-the-ornstein-uhlenbeck-process-can-be-considered-as-the-continuous-time-anal)
- [Covariance Functions](https://en.wikipedia.org/wiki/Gaussian_process#Usual_covariance_functions)